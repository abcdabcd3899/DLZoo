{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEN4rk_gU3eV"
      },
      "source": [
        "!pip install d2l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxHcDUTgVGcR"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "batch_size, num_steps = 32, 35\n",
        "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3ScZMJDVJxK"
      },
      "source": [
        "def get_params(vocab_size, num_hiddens, device):\n",
        "    num_inputs = num_outputs = vocab_size\n",
        "\n",
        "    def normal(shape):\n",
        "        return torch.randn(size=shape, device=device) * 0.01\n",
        "\n",
        "    def three():\n",
        "        return (normal(\n",
        "            (num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)),\n",
        "                torch.zeros(num_hiddens, device=device))\n",
        "\n",
        "    W_xz, W_hz, b_z = three()  # update gate\n",
        "    W_xr, W_hr, b_r = three()  # reset gate\n",
        "    W_xh, W_hh, b_h = three()  # 对两个输入 Xt和Ht-1的transformation\n",
        "    # 输出层参数\n",
        "    W_hq = normal((num_hiddens, num_outputs))\n",
        "    b_q = torch.zeros(num_outputs, device=device)\n",
        "    # 附加梯度\n",
        "    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]\n",
        "    for param in params:\n",
        "        param.requires_grad_(True)\n",
        "    return params\n",
        "\n",
        "def init_gru_state(batch_size, num_hiddens, device):\n",
        "    return (torch.zeros((batch_size, num_hiddens), device=device),)\n",
        "\n",
        "def gru(inputs, state, params):\n",
        "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
        "    H, = state\n",
        "    outputs = []\n",
        "    for X in inputs:\n",
        "        Z = torch.sigmoid(torch.mm(X,W_xz) + torch.mm(H ,W_hz) + b_z)\n",
        "        R = torch.sigmoid(torch.mm(X, W_xr) + torch.mm(H, W_hr) + b_r)\n",
        "        H_tilda = torch.tanh(torch.mm(X, W_xh) + ((R * H)  @W_hh) + b_h)  # candidate hidden state\n",
        "        H = Z * H + (1 - Z) * H_tilda\n",
        "        Y = H @ W_hq + b_q\n",
        "        outputs.append(Y)\n",
        "    return torch.cat(outputs, dim=0), (H,)\n",
        "\n",
        "vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()\n",
        "num_epochs, lr = 500, 1\n",
        "model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params,\n",
        "                            init_gru_state, gru)\n",
        "d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}